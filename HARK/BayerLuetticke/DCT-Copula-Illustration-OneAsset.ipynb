{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook seems to have been abandoned partway through.  It should either be finished or deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction in [Bayer and Luetticke (2018)](https://cepr.org/active/publications/discussion_papers/dp.php?dpno=13071)\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/econ-ark/HARK/BayerLuetticke?filepath=HARK%2FBayerLuetticke%2FDCT-Copula-Illustration.ipynb)\n",
    "\n",
    "This companion to the [main notebook](TwoAsset.ipynb) explains in more detail how the authors reduce the dimensionality of their problem\n",
    "\n",
    "- Based on original slides by Christian Bayer and Ralph Luetticke \n",
    "- Original Jupyter notebook by Seungcheol Lee \n",
    "- Further edits by Chris Carroll, Tao Wang \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "In Steady-state Equilibrium (StE), in any given period, a consumer in state $s$ (which comprises liquid assets $m$, illiquid assets $k$, and human capital $\\newcommand{hLev}{h}\\hLev$) has two key choices:\n",
    "1. To adjust ('a') or not adjust ('n') their holdings of illiquid assets $k$\n",
    "1. Contingent on that choice, decide the level of consumption, yielding consumption functions:\n",
    "    * $c_n(s)$ - nonadjusters\n",
    "    * $c_a(s)$ - adjusters\n",
    "\n",
    "The usual envelope theorem applies here, so marginal value wrt the liquid asset equals marginal utility with respect to consumption:\n",
    "$[\\frac{d v}{d m} = \\frac{d u}{d c}]$.\n",
    "In practice, the authors solve their problem using the marginal value of money $\\texttt{Vm} = dv/dm$, but because the marginal utility function is invertible it is trivial to recover $\\texttt{c}$ from $(u^{\\prime})^{-1}(\\texttt{Vm} )$.  The consumption function is therefore computed from the $\\texttt{Vm}$ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Setup stuff\n",
    "\n",
    "# This is a jupytext paired notebook that autogenerates a corresponding .py file\n",
    "# which can be executed from a terminal command line via \"ipython [name].py\"\n",
    "# But a terminal does not permit inline figures, so we need to test jupyter vs terminal\n",
    "# Google \"how can I check if code is executed in the ipython notebook\"\n",
    "def in_ipynb():\n",
    "    try:\n",
    "        if str(type(get_ipython())) == \"<class 'ipykernel.zmqshell.ZMQInteractiveShell'>\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "# Determine whether to make the figures inline (for spyder or jupyter)\n",
    "# vs whatever is the automatic setting that will apply if run from the terminal\n",
    "if in_ipynb():\n",
    "    # %matplotlib inline generates a syntax error when run from the shell\n",
    "    # so do this instead\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline') \n",
    "else:\n",
    "    get_ipython().run_line_magic('matplotlib', 'auto') \n",
    "    \n",
    "# The tools for navigating the filesystem\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Find pathname to this file:\n",
    "my_file_path = os.path.dirname(os.path.abspath(\"DCT-Copula-Illustration-OneAsset.ipynb\"))\n",
    "\n",
    "# Relative directory for pickled code\n",
    "code_dir = os.path.join(my_file_path, \"Assets/One\") \n",
    "\n",
    "sys.path.insert(0, code_dir)\n",
    "sys.path.insert(0, my_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load precalculated Stationary Equilibrium (StE) object EX3SS\n",
    "\n",
    "import pickle\n",
    "os.chdir(code_dir) # Go to the directory with pickled code\n",
    "\n",
    "EX2SS=pickle.load(open(\"EX2SS.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Data/Code/ARK/HARKive/HARK/HARK/BayerLuetticke/Assets/One'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Data/Code/ARK/HARKive/HARK/HARK/BayerLuetticke'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['par', 'mpar', 'grid', 'Output', 'targets', 'Vm', 'joint_distr', 'Copula', 'c_policy', 'm_policy', 'mutil_c', 'P_H'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EX2SS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions\n",
    "\n",
    "The imported StE solution to the problem represents the functions at a set of gridpoints of\n",
    "   * liquid assets ($n_m$ points), illiquid assets ($n_k$), and human capital ($n_h$)\n",
    "      * In the code these are $\\{\\texttt{nm,nk,nh}\\}$\n",
    "\n",
    "So even if the grids are fairly sparse for each state variable, the total number of combinations of the idiosyncratic state gridpoints is large: $n = n_m \\times n_k \\times n_h$.  So, e.g., $\\bar{c}$ is a set of size $n$ containing the level of consumption at each possible _combination_ of gridpoints.\n",
    "\n",
    "In the \"real\" micro problem, it would almost never happen that a continuous variable like $m$ would end up being exactly equal to one of the prespecified gridpoints. But the functions need to be evaluated at such non-grid points.  This is addressed by linear interpolation.  That is, if, say, the grid had $m_{8} = 40$ and $m_{9} = 50$ then and a consumer ended up with $m = 45$ then the approximation is that $\\tilde{c}(45) = 0.5 \\bar{c}_{8} + 0.5 \\bar{c}_{9}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 2,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c is of dimension: (500, 4)\n",
      "Vm is of dimension:(500, 4)\n",
      "For convenience, these are all constructed from the same exogenous grids:\n",
      "500 gridpoints for liquid assets;\n",
      "4 gridpoints for individual productivity.\n",
      "\n",
      "Therefore, the joint distribution is of size: \n",
      "500 * 4 = 2000\n"
     ]
    }
   ],
   "source": [
    "# Show dimensions of the consumer's problem (state space)\n",
    "\n",
    "print('c is of dimension: ' + str(EX2SS['mutil_c'].shape))\n",
    "print('Vm is of dimension:' + str(EX2SS['Vm'].shape))\n",
    "\n",
    "print('For convenience, these are all constructed from the same exogenous grids:')\n",
    "print(str(len(EX2SS['grid']['m']))+' gridpoints for liquid assets;')\n",
    "print(str(len(EX2SS['grid']['h']))+' gridpoints for individual productivity.')\n",
    "print('')\n",
    "print('Therefore, the joint distribution is of size: ')\n",
    "print(str(EX2SS['mpar']['nm'])+\n",
    "    ' * '+str(EX2SS['mpar']['nh'])+\n",
    "   ' = '+ str(EX2SS['mpar']['nm']*EX2SS['mpar']['nh']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction\n",
    "\n",
    "The authors use different dimensionality reduction methods for the consumer's problem and the distribution across idiosyncratic states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representing the consumer's problem with Basis Functions\n",
    "\n",
    "The idea is to find an efficient \"compressed\" representation of our functions (e.g., the consumption function), which BL do using tools originally developed for image compression.  The analogy to image compression is that nearby pixels are likely to have identical or very similar colors, so we need only to find an efficient way to represent how the colors _change_ from one pixel to nearby ones.  Similarly, consumption at a given point $s_{i}$ is likely to be close to consumption point at another point $s_{j}$ that is \"close\" in the state space (similar wealth, income, etc), so a function that captures that similarity efficiently can preserve most of the information without keeping all of the points.\n",
    "\n",
    "Like linear interpolation, the [DCT transformation](https://en.wikipedia.org/wiki/Discrete_cosine_transform) is a method of representing a continuous function using a finite set of numbers. It uses a set of independent [basis functions](https://en.wikipedia.org/wiki/Basis_function) to do this.\n",
    "\n",
    "But it turns out that some of those basis functions are much more important than others in representing the steady-state functions. Dimension reduction is accomplished by basically ignoring all basis functions that make \"small enough\" contributions to the representation of the function.  \n",
    "\n",
    "##### When might this go wrong?\n",
    "\n",
    "Suppose the consumption function changes in a recession in ways that change behavior radically at some states.  Like, suppose unemployment almost never happens in steady state, but it can happen in temporary recessions.  Suppose further that, even for employed people, in a recession, _worries_ about unemployment cause many of them to prudently withdraw some of their illiquid assets -- behavior opposite of what people in the same state would be doing during expansions.  In that case, the basis functions that represented the steady state function would have had no incentive to be able to represent well the part of the space that is never seen in steady state, so any functions that might help do so might well have been dropped in the dimension reduction stage.\n",
    "\n",
    "On the whole, it seems unlikely that this kind of thing is a major problem, because the vast majority of the variation that people experience is idiosyncratic.  There is always unemployment, for example; it just moves up and down a bit with aggregate shocks, but since the experience of unemployment is in fact well represented in the steady state the method should have no trouble capturing it.\n",
    "\n",
    "Where the method might have more trouble is in representing economies in which there are multiple equilibria in which behavior is quite different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the distribution of agents across states: Copula\n",
    "\n",
    "The other tool the authors use is the [\"copula\"](https://en.wikipedia.org/wiki/Copula_(probability_theory)), which allows us to represent the distribution of people across idiosyncratic states efficiently\n",
    "\n",
    "The copula is computed from the joint distribution of states in StE and will be used to transform the [marginal distributions](https://en.wikipedia.org/wiki/Marginal_distribution) back to joint distributions.  (For an illustration of how the assumptions used when modeling asset price distributions using copulas can fail see [Salmon](https://www.wired.com/2009/02/wp-quant/))\n",
    "\n",
    "   * A copula is a representation of the joint distribution expressed using a mapping between the uniform joint CDF and the marginal distributions of the variables\n",
    "   \n",
    "   * The crucial assumption is that what aggregate shocks do is to squeeze or distort the steady state distribution, but leave the rank structure of the distribution the same\n",
    "      * An example of when this might not hold is the following.  Suppose that in expansions, the people at the top of the distribution of illiquid assets (the top 1 percent, say) are also at the top 1 percent of liquid assets. But in recessions the bottom 99 percent get angry at the top 1 percent of illiquid asset holders and confiscate part of their liquid assets (the illiquid assets can't be confiscated quickly because they are illiquid). Now the people in the top 99 percent of illiquid assets might be in the _bottom_ 1 percent of liquid assets.\n",
    "   \n",
    "- In this case we just need to represent how the mapping from ranks into levels of assets\n",
    "\n",
    "- This reduces the number of points for which we need to track transitions from $3600 = 30 \\times 30 \\times 4$ to $64 = 30+30+4$.  Or the total number of points we need to contemplate goes from $3600^2 \\approx 13 $million to $64^2=4096$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'bounds_error',\n",
       " 'fill_value',\n",
       " 'tck',\n",
       " 'x',\n",
       " 'x_max',\n",
       " 'x_min',\n",
       " 'y',\n",
       " 'y_max',\n",
       " 'y_min',\n",
       " 'z']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(EX2SS['Copula'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Get some specs about the copula, which is precomputed in the EX3SS object\n",
    "\n",
    "#print('The copula consists of two parts: gridpoints and values at those gridpoints:'+ \\\n",
    "#      '\\n gridpoints have dimensionality of '+str(EX2SS['Copula']['grid'].shape) + \\\n",
    "#      '\\n where the first element is total number of gridpoints' + \\\n",
    "#      '\\n and the second element is number of idiosyncratic state variables' + \\\n",
    "#      '\\n whose values also are of dimension of '+str(EX2SS['Copula']['value'].shape[0]) + \\\n",
    "#      '\\n each entry of which is the probability that all three of the'\n",
    "#      '\\n state variables are below the corresponding point.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys \n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import matrix_rank\n",
    "import scipy as sc\n",
    "from scipy.stats import norm \n",
    "from scipy.interpolate import interp1d, interp2d, griddata, RegularGridInterpolator, interpn\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, cpu_count, Process\n",
    "from math import ceil\n",
    "import math as mt\n",
    "from scipy import sparse as sp  # used to work with sparse matrices\n",
    "from scipy import linalg   #linear algebra \n",
    "from math import log, cos, pi, sqrt\n",
    "import time\n",
    "from SharedFunc2 import Transition, ExTransitions, GenWeight, Tauchen  # two functions in 2-asset cases \n",
    "                                                                       # are not available for 1 asset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.io #scipy input and output\n",
    "import scipy.fftpack as sf  # scipy discrete fourier transforms\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import cm\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Wrapping one-asset codes from BayerLuetticke. Super long. No need to unfold for most purposes of this notebook\n",
    "\n",
    "\n",
    "class FluctuationsOneAssetIOUs:\n",
    "    \n",
    "    def __init__(self, par, mpar, grid, Output, targets, Vm, joint_distr, Copula, c_policy, m_policy, mutil_c, P_H):\n",
    "         \n",
    "        self.par = par\n",
    "        self.mpar = mpar\n",
    "        self.grid = grid\n",
    "        self.Output = Output\n",
    "        self.targets = targets\n",
    "        self.Vm = Vm\n",
    "        self.joint_distr = joint_distr\n",
    "        self.Copula = Copula\n",
    "        self.c_policy = c_policy\n",
    "        self.m_policy = m_policy\n",
    "        self.mutil_c = mutil_c\n",
    "        self.P_H = P_H\n",
    "        \n",
    "        \n",
    "    def StateReduc(self):\n",
    "        invutil = lambda x : ((1-self.par['xi'])*x)**(1./(1-self.par['xi']))\n",
    "        invmutil = lambda x : (1./x)**(1./self.par['xi'])\n",
    "\n",
    "        Xss=np.vstack((np.sum(self.joint_distr.copy(),axis=1), np.transpose(np.sum(self.joint_distr.copy(),axis=0)),np.log(self.par['RB']),0))\n",
    "        Yss=np.vstack((invmutil(np.reshape(self.mutil_c.copy(),(np.product(self.mutil_c.shape),1),order='F')),np.log(self.par['PI']),np.log(self.targets['Y']),np.log(self.targets['W']),np.log(self.targets['PROFITS']),np.log(self.targets['N']),self.targets['B'],self.targets['G']))\n",
    "        ## Construct Chebyshev Polynomials to describe deviations of policy from SS\n",
    "        Poly=[]\n",
    "        maxlevel=max(self.mpar['nm'],self.mpar['nh'])\n",
    "        \n",
    "        Tm=np.cos(pi*np.arange(0,maxlevel,1)[np.newaxis].T * (np.linspace(0.5/self.mpar['nm']/2, 1-0.5/self.mpar['nm']*2, self.mpar['nm'])[np.newaxis])).T\n",
    "        Th=np.cos(pi*np.arange(0,maxlevel,1)[np.newaxis].T * (np.linspace(0.5/(self.mpar['nh']-1), 1-0.5/(self.mpar['nh']-1), (self.mpar['nh']-1))[np.newaxis])).T\n",
    "\n",
    "        self.mpar['maxdim']=10\n",
    "        \n",
    "        for j1 in range(0, max(np.shape(self.grid['h']))-1):\n",
    "          for j3 in range(0, max(np.shape(self.grid['m']))):\n",
    "            if j1 + j3 < self.mpar['maxdim']-2:\n",
    "                TT1,TT3=np.meshgrid(Tm[:,j3], np.vstack((Th[:,j1][np.newaxis].T,0.)), indexing='ij')\n",
    "                Poly.append((TT1.flatten(order='F')*TT3.flatten(order='F'))[np.newaxis].T)\n",
    "\n",
    "        for j2 in range(0,max(np.shape(self.grid['m']))):\n",
    "            if j2 < self.mpar['maxdim']- 2:\n",
    "               TT1,TT3=np.meshgrid(Tm[:,j2], np.vstack((np.zeros(max(np.shape(self.grid['h']))-1)[np.newaxis].T,1)), indexing='ij')\n",
    "               Poly.append((TT1.flatten(order='F')*TT3.flatten(order='F'))[np.newaxis].T)\n",
    "\n",
    "        Poly=np.squeeze(np.asarray(Poly)).T\n",
    "        InvCheb=linalg.solve(np.dot(Poly.T,Poly),Poly.T)\n",
    "        \n",
    "        ## Construct function such that perturbed marginal distributions still integrate to 1\n",
    "        Gamma=np.zeros((self.mpar['nm'] + self.mpar['nh'], self.mpar['nm'] + self.mpar['nh'] - 3))\n",
    "\n",
    "        for j in range(0,self.mpar['nm'] - 1):\n",
    "              Gamma[0:self.mpar['nm'],j]= -np.squeeze(Xss[0:self.mpar['nm']])\n",
    "              Gamma[j,j]= 1. - Xss[j]\n",
    "              Gamma[j,j]=Gamma[j,j] - sum(Gamma[0:self.mpar['nm'],j])\n",
    "        \n",
    "        bb=self.mpar['nm']\n",
    "        \n",
    "        for j in range(0,self.mpar['nh'] - 2):\n",
    "              Gamma[bb + np.asarray(range(0,self.mpar['nh'] - 1)), bb + j-1]= -np.squeeze(Xss[bb + np.asarray(range(0,self.mpar['nh'] - 1))])\n",
    "              Gamma[bb + j,bb - 1 + j]= 1 - Xss[bb + j]\n",
    "              Gamma[bb + j,bb - 1 + j]= Gamma[bb + j,bb - 1 + j] - sum(Gamma[bb + np.asarray(range(0,self.mpar['nh'] - 1)), bb - 1 + j])\n",
    "  \n",
    "            ## Collect all functions used for perturbation\n",
    "        n1=np.array(np.shape(Poly))\n",
    "        n2=np.array(np.shape(Gamma))\n",
    "\n",
    "        # Produce matrices to reduce state-space\n",
    "        oc=len(Yss) - n1[0]\n",
    "        os=len(Xss) - (self.mpar['nm'] + self.mpar['nh'])\n",
    "\n",
    "        InvGamma = np.zeros((1*n1[0] + n2[1] + 2 + oc, 1*n1[1] + n2[1] + 2 + oc))\n",
    "        Gamma_state = sp.coo_matrix((Gamma))\n",
    "        InvGamma[0:n2[0]+2, 0:n2[0]+2] = np.eye(n2[0] + 2)\n",
    "\n",
    "        Gamma_control=np.zeros((1*n1[0] + oc, 1*n1[1] + oc))\n",
    "        Gamma_control[0:n1[0],0:n1[1]]=Poly\n",
    "        InvGamma[(n2[1]+2+0):(n2[1]+2+n1[0]), (n2[1]+2+0):(n2[1]+2+n1[1])] = InvCheb.T\n",
    "\n",
    "        Gamma_control[(1*n1[0]+0):(1*n1[0]+oc), (1*n1[1]+0):(1*n1[1]+oc)] = np.eye(oc)\n",
    "        InvGamma[(n2[1]+1*n1[0]+2+0):(n2[1]+1*n1[0]+2+oc), (n2[1]+1*n1[1]+2+0):(n2[1]+1*n1[1]+2+oc)] = np.eye(oc)\n",
    "\n",
    "        InvGamma=InvGamma.T\n",
    "        InvGamma=sp.coo_matrix((InvGamma))\n",
    "\n",
    "        self.mpar['numstates'] = n2[1] + 2\n",
    "        self.mpar['numcontrols'] = n1[1] + oc\n",
    "\n",
    "\n",
    "                 \n",
    "        aggrshock           = 'MP'\n",
    "        self.par['rhoS']    = 0.0      # Persistence of variance\n",
    "        self.par['sigmaS']  = 0.001    # STD of variance shocks\n",
    "\n",
    "        \n",
    "        return {'Xss': Xss, 'Yss':Yss, 'Gamma_state': Gamma_state, \n",
    "                'Gamma_control': Gamma_control, 'InvGamma':InvGamma, \n",
    "                'par':self.par, 'mpar':self.mpar, 'aggrshock':aggrshock, 'oc':oc,\n",
    "                'Copula':self.Copula,'grid':self.grid,'targets':self.targets,'P_H':self.P_H, \n",
    "                'joint_distr': self.joint_distr, 'os':os, 'Output': self.Output}\n",
    "        \n",
    "\n",
    "\n",
    "def SGU_solver(Xss,Yss,Gamma_state,Gamma_control,InvGamma,Copula,par,mpar,grid,targets,P_H,aggrshock,oc): #\n",
    "\n",
    "    State       = np.zeros((mpar['numstates'],1))\n",
    "    State_m     = State.copy()\n",
    "    Contr       = np.zeros((mpar['numcontrols'],1))\n",
    "    Contr_m     = Contr.copy()\n",
    "        \n",
    "\n",
    "    F = lambda S, S_m, C, C_m : Fsys(S, S_m, C, C_m,\n",
    "                                         Xss,Yss,Gamma_state,Gamma_control,InvGamma,\n",
    "                                         Copula,par,mpar,grid,targets,P_H,aggrshock,oc)\n",
    "        \n",
    "      \n",
    "    start_time = time.clock() \n",
    "    result_F = F(State,State_m,Contr,Contr_m)\n",
    "    end_time   = time.clock()\n",
    "    print('Elapsed time is ', (end_time-start_time), ' seconds.')\n",
    "    Fb=result_F['Difference']\n",
    "        \n",
    "    pool=cpu_count()/2-1\n",
    "\n",
    "    F1=np.zeros((mpar['numstates'] + mpar['numcontrols'], mpar['numstates']))\n",
    "    F2=np.zeros((mpar['numstates'] + mpar['numcontrols'], mpar['numcontrols']))\n",
    "    F3=np.zeros((mpar['numstates'] + mpar['numcontrols'], mpar['numstates']))\n",
    "    F4=np.asmatrix(np.vstack((np.zeros((mpar['numstates'], mpar['numcontrols'])), np.eye(mpar['numcontrols'],mpar['numcontrols']) )))\n",
    "        \n",
    "    print('Use Schmitt Grohe Uribe Algorithm')\n",
    "    print(' A *E[xprime uprime] =B*[x u]')\n",
    "    print(' A = (dF/dxprimek dF/duprime), B =-(dF/dx dF/du)')\n",
    "        \n",
    "    numscale=1\n",
    "    pnum=pool\n",
    "    packagesize=int(ceil(mpar['numstates'] / float(3*pnum)))\n",
    "    blocks=int(ceil(mpar['numstates'] / float(packagesize) ))\n",
    "\n",
    "    par['scaleval1'] = 1e-9\n",
    "    par['scaleval2'] = 1e-6\n",
    "        \n",
    "    start_time = time.clock()\n",
    "    print('Computing Jacobian F1=DF/DXprime F3 =DF/DX')\n",
    "    print('Total number of parallel blocks: ', str(blocks), '.')\n",
    "        \n",
    "    FF1=[]\n",
    "    FF3=[]\n",
    "        \n",
    "    for bl in range(0,blocks):\n",
    "        range_= range(bl*packagesize, min(packagesize*(bl+1),mpar['numstates']))\n",
    "        DF1=np.asmatrix( np.zeros((len(Fb),len(range_))) )\n",
    "        DF3=np.asmatrix( np.zeros((len(Fb),len(range_))) )\n",
    "        cc=np.zeros((mpar['numcontrols'],1))\n",
    "        ss=np.zeros((mpar['numstates'],1))\n",
    "        for Xct in range_:\n",
    "            X=np.zeros((mpar['numstates'],1))\n",
    "            h=par['scaleval1']\n",
    "            X[Xct]=h\n",
    "            Fx=F(ss,X,cc,cc)\n",
    "            DF3[:, Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "            Fx=F(X,ss,cc,cc)\n",
    "            DF1[:, Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        if sum(range_ == mpar['numstates'] - 2) == 1:\n",
    "            Xct=mpar['numstates'] - 2\n",
    "            X=np.zeros((mpar['numstates'],1))\n",
    "            h=par['scaleval2']\n",
    "            X[Xct]=h\n",
    "            Fx=F(ss,X,cc,cc)\n",
    "            DF3[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "            Fx=F(X,ss,cc,cc)\n",
    "            DF1[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        if sum(range_ == mpar['numstates'] - 1) == 1:\n",
    "            Xct=mpar['numstates'] - 1\n",
    "            X=np.zeros((mpar['numstates'],1))\n",
    "            h=par['scaleval2']\n",
    "            X[Xct]=h\n",
    "            Fx=F(ss,X,cc,cc)\n",
    "            DF3[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "            Fx=F(X,ss,cc,cc)\n",
    "            DF1[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        FF1.append(DF1.copy())\n",
    "        FF3.append(DF3.copy())\n",
    "        print('Block number: ', str(bl),' done.')\n",
    "\n",
    "    for i in range(0,int(ceil(mpar['numstates'] / float(packagesize)) )):\n",
    "        range_= range(i*packagesize, min(packagesize*(i+1),mpar['numstates']))\n",
    "        F1[:,range_]=FF1[i]\n",
    "        F3[:,range_]=FF3[i]\n",
    "\n",
    "    end_time   = time.clock()\n",
    "    print('Elapsed time is ', (end_time-start_time), ' seconds.')\n",
    "\n",
    "    # jacobian wrt Y'\n",
    "    packagesize=int(ceil(mpar['numcontrols'] / (3.0*pnum)))\n",
    "    blocks=int(ceil(mpar['numcontrols'] / float(packagesize)))\n",
    "    print('Computing Jacobian F2 - DF/DYprime')\n",
    "    print('Total number of parallel blocks: ', str(blocks),'.')\n",
    "\n",
    "    FF=[]\n",
    "        \n",
    "    start_time = time.clock()\n",
    "        \n",
    "    for bl in range(0,blocks):\n",
    "        range_= range(bl*packagesize,min(packagesize*(bl+1),mpar['numcontrols']))\n",
    "        DF2=np.asmatrix(np.zeros((len(Fb),len(range_))))\n",
    "        cc=np.zeros((mpar['numcontrols'],1))\n",
    "        ss=np.zeros((mpar['numstates'],1))\n",
    "        for Yct in range_:\n",
    "            Y=np.zeros((mpar['numcontrols'],1))\n",
    "            h=par['scaleval2']\n",
    "            Y[Yct]=h\n",
    "            Fx=F(ss,ss,Y,cc)\n",
    "            DF2[:,Yct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        FF.append(DF2.copy())\n",
    "        print('Block number: ',str(bl),' done.')\n",
    "\n",
    "        \n",
    "    for i in range(0,int(ceil(mpar['numcontrols'] / float(packagesize) ))):\n",
    "        range_=range(i*packagesize, min(packagesize*(i+1),mpar['numcontrols']))\n",
    "        F2[:,range_]=FF[i]\n",
    "        \n",
    "    end_time = time.clock()\n",
    "    print('Elapsed time is ', (end_time-start_time), ' seconds.')\n",
    "        \n",
    "        \n",
    "    FF=[]\n",
    "    FF1=[]\n",
    "    FF3=[]\n",
    "        \n",
    "    cc=np.zeros((mpar['numcontrols'],1))\n",
    "    ss=np.zeros((mpar['numstates'],1))\n",
    "    \n",
    "    for Yct in range(0, oc):\n",
    "        Y=np.zeros((mpar['numcontrols'],1))\n",
    "        h=par['scaleval2']\n",
    "        Y[-1-Yct]=h\n",
    "        Fx=F(ss,ss,cc,Y)\n",
    "        F4[:,-1 - Yct]=(Fx['Difference'] - Fb) / h\n",
    "        \n",
    "   \n",
    "    s,t,Q,Z=linalg.qz(np.hstack((F1,F2)), -np.hstack((F3,F4)), output='complex')\n",
    "    abst = abs(np.diag(t))*(abs(np.diag(t))!=0.)+  (abs(np.diag(t))==0.)*10**(-11)\n",
    "    #relev=np.divide(abs(np.diag(s)), abs(np.diag(t)))\n",
    "    relev=np.divide(abs(np.diag(s)), abst)    \n",
    "    \n",
    "    ll=sorted(relev)\n",
    "    slt=relev >= 1\n",
    "    nk=sum(slt)\n",
    "    slt=1*slt\n",
    "    mpar['overrideEigen']=1\n",
    "\n",
    "    s_ord,t_ord,__,__,__,Z_ord=linalg.ordqz(np.hstack((F1,F2)), -np.hstack((F3,F4)), sort='ouc', output='complex')\n",
    "    \n",
    "    def sortOverridEigen(x, y):\n",
    "        out = np.empty_like(x, dtype=bool)\n",
    "        xzero = (x == 0)\n",
    "        yzero = (y == 0)\n",
    "        out[xzero & yzero] = False\n",
    "        out[~xzero & yzero] = True\n",
    "        out[~yzero] = (abs(x[~yzero]/y[~yzero]) > ll[-1 - mpar['numstates']])\n",
    "        return out        \n",
    "    \n",
    "    if nk > mpar['numstates']:\n",
    "       if mpar['overrideEigen']:\n",
    "          print('Warning: The Equilibrium is Locally Indeterminate, critical eigenvalue shifted to: ', str(ll[-1 - mpar['numstates']]))\n",
    "          slt=relev > ll[-1 - mpar['numstates']]\n",
    "          nk=sum(slt)\n",
    "          s_ord,t_ord,__,__,__,Z_ord=linalg.ordqz(np.hstack((F1,F2)), -np.hstack((F3,F4)), sort=sortOverridEigen, output='complex')\n",
    "          \n",
    "       else:\n",
    "          print('No Local Equilibrium Exists, last eigenvalue: ', str(ll[-1 - mpar['numstates']]))\n",
    "        \n",
    "    elif nk < mpar['numstates']:\n",
    "       if mpar['overrideEigen']:\n",
    "          print('Warning: No Local Equilibrium Exists, critical eigenvalue shifted to: ', str(ll[-1 - mpar['numstates']]))\n",
    "          slt=relev > ll[-1 - mpar['numstates']]\n",
    "          nk=sum(slt)\n",
    "          s_ord,t_ord,__,__,__,Z_ord=linalg.ordqz(np.hstack((F1,F2)), -np.hstack((F3,F4)), sort=sortOverridEigen, output='complex')\n",
    "          \n",
    "       else:\n",
    "          print('No Local Equilibrium Exists, last eigenvalue: ', str(ll[-1 - mpar['numstates']]))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    z21=Z_ord[nk:,0:nk]\n",
    "    z11=Z_ord[0:nk,0:nk]\n",
    "    s11=s_ord[0:nk,0:nk]\n",
    "    t11=t_ord[0:nk,0:nk]\n",
    "    \n",
    "    if matrix_rank(z11) < nk:\n",
    "       print('Warning: invertibility condition violated')\n",
    "              \n",
    "#    z11i=linalg.solve(z11,np.eye(nk)) # A\\B, Ax=B\n",
    "#    gx_= np.dot(z21,z11i)\n",
    "#    gx=gx_.real\n",
    "#    hx_=np.dot(z11,np.dot(linalg.solve(s11,t11),z11i))\n",
    "#    hx=hx_.real           \n",
    "\n",
    "    z11i  = np.dot(np.linalg.inv(z11), np.eye(nk)) # compute the solution\n",
    "\n",
    "    gx = np.real(np.dot(z21,z11i))\n",
    "    hx = np.real(np.dot(z11,np.dot(np.dot(np.linalg.inv(s11),t11),z11i)))\n",
    "         \n",
    "    return{'hx': hx, 'gx': gx, 'F1': F1, 'F2': F2, 'F3': F3, 'F4': F4, 'par': par }\n",
    "\n",
    "        \n",
    "def plot_IRF(mpar,par,gx,hx,joint_distr,Gamma_state,grid,targets,os,oc,Output):\n",
    "        \n",
    "    x0 = np.zeros((mpar['numstates'],1))\n",
    "    x0[-1] = par['sigmaS']\n",
    "        \n",
    "    MX = np.vstack((np.eye(len(x0)), gx))\n",
    "    IRF_state_sparse=[]\n",
    "    x=x0.copy()\n",
    "    mpar['maxlag']=16\n",
    "        \n",
    "    for t in range(0,mpar['maxlag']):\n",
    "        IRF_state_sparse.append(np.dot(MX,x))\n",
    "        x=np.dot(hx,x)\n",
    "        \n",
    "    IRF_state_sparse = np.asmatrix(np.squeeze(np.asarray(IRF_state_sparse))).T\n",
    "        \n",
    "    aux = np.sum(np.sum(joint_distr,1),0)\n",
    "        \n",
    "    scale={}\n",
    "    scale['h'] = np.tile(np.vstack((1,aux[-1])),(1,mpar['maxlag']))\n",
    "        \n",
    "    IRF_distr = Gamma_state*IRF_state_sparse[:mpar['numstates']-2,:mpar['maxlag']]\n",
    "        \n",
    "    # preparation\n",
    "        \n",
    "    IRF_H = 100*grid['h'][:-1]*IRF_distr[mpar['nm']:mpar['nm']+mpar['nh']-1,1:]/par['H']\n",
    "    IRF_M = 100*grid['m']*IRF_distr[:mpar['nm'],1:]/targets['Y']\n",
    "    M = 100*grid['m']*IRF_distr[:mpar['nm'],:]+grid['B']\n",
    "    IRF_RB = 100*IRF_state_sparse[mpar['numstates']-os,1:]\n",
    "    IRF_S=100*IRF_state_sparse[mpar['numstates']-os+1,:-1]\n",
    "        \n",
    "    Y=targets['Y']*(1+IRF_state_sparse[-1-oc+2, :-1])\n",
    "    G=targets['G']*(1+IRF_state_sparse[-1-oc+7, :-1])\n",
    "    C=Y-G;\n",
    "    \n",
    "    IRF_C=100*np.log(C/(targets['Y']-targets['G']))\n",
    "    IRF_Y=100*IRF_state_sparse[-1-oc+2, :-1]\n",
    "    IRF_G=100*IRF_state_sparse[-1-oc+7, :-1]\n",
    "    IRF_N=100*IRF_state_sparse[-1-oc+5, :-1]\n",
    "    IRF_PI=100*100*IRF_state_sparse[-1-oc+1, :-1]\n",
    "        \n",
    "    PI=1+IRF_state_sparse[-1-oc+1, :-1]\n",
    "    RB=par['RB']+(IRF_state_sparse[mpar['numstates']-os,1:])\n",
    "    IRF_RB=100*100*(RB-par['RB'])\n",
    "    IRF_RBREAL=100*100*(RB/PI-par['RB'])\n",
    "        \n",
    "    f_Y = plt.figure(1)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_Y)),label='IRF_Y')\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "#    patch_Y = mpatches.Patch(color='blue', label='IRF_Y_thetapi')\n",
    "#    plt.legend(handles=[patch_Y])\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "#    f_Y.show()\n",
    "#        \n",
    "    f_C = plt.figure(2)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_C)),label='IRF_C')\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "#    f_C.show()\n",
    "        \n",
    "    f_M = plt.figure(3)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_M)), label='IRF_M')\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "#    f_M.show()\n",
    "\n",
    "    f_H = plt.figure(4)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_H)), label='IRF_H')\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "#    f_H.show()\n",
    "        \n",
    "    f_S = plt.figure(5)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_S)), label='IRF_S')\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "#    f_S.show()        \n",
    "        \n",
    "    f_RBPI = plt.figure(6)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_RB)), label='nominal', color='blue', linestyle='--')\n",
    "    line2,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_RBREAL)), label='real', color='red')\n",
    "    plt.legend(handles=[line1, line2])\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis point') \n",
    "#    f_RBPI.show()\n",
    "        \n",
    "    f_PI = plt.figure(7)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_PI)), label='IRF_PI')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis point') \n",
    "#    f_PI.show()\n",
    "        \n",
    "    f_N = plt.figure(8)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_N)), label='IRF_N')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "#    f_N.show()\n",
    "\n",
    "    f_G = plt.figure(9)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_G)), label='IRF_G')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']-1),np.zeros((mpar['maxlag']-1)),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "#    f_G.show()        \n",
    "        \n",
    "def Fsys(State, Stateminus, Control_sparse, Controlminus_sparse, StateSS, ControlSS, \n",
    "         Gamma_state, Gamma_control, InvGamma, Copula, par, mpar, grid, targets, P, aggrshock, oc):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    par : dict\n",
    "        par['mu'] = par.mu : float\n",
    "        par['beta'] = par.beta : float\n",
    "        par['kappa'] = par.kappa : float\n",
    "        par['tau'] = par.tau : float\n",
    "        par['alpha'] = par.alpha : float\n",
    "        par['gamma'] = par.gamma : float\n",
    "        par['xi]= par.xi : float\n",
    "        par['rhoS'] = par.rhoS : float\n",
    "        par['profitshare'] = par.profitshare : float\n",
    "        par['borrwedge'] = par.borrwedge : float\n",
    "        par['RB']\n",
    "        par['rho_R']\n",
    "        par['PI']\n",
    "        par['theta_pi']\n",
    "    mpar : dict\n",
    "        mpar['nm']=mparnm : int\n",
    "        mpar['nh']=mparnh : int\n",
    "    grid : dict\n",
    "        grid['m']=grid.m : np.array (row vector)\n",
    "        grid['h']=grid.h : np.array\n",
    "        grid['boundsH']=grid.boundsH : np.array (1,mpar['nh'])\n",
    "        grid['K'] = grid.K : float\n",
    "    StateSS : np.array (column vector)   \n",
    "    Copula : function\n",
    "    targets : dict\n",
    "        targets['B'] : float\n",
    "    oc: int\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## Initialization\n",
    "#    mutil = lambda x : 1./(x**par['xi'])\n",
    "    mutil = lambda x : 1./np.power(x,par['xi'])\n",
    "#    invmutil = lambda x : (1./x)**(1./par['xi'])\n",
    "    invmutil = lambda x : np.power(1./x,1./par['xi'])\n",
    "    \n",
    "    # Generate meshes for b,k,h\n",
    "    meshesm, meshesh = np.meshgrid(grid['m'],grid['h'],indexing='ij')\n",
    "    meshes ={'m':meshesm, 'h':meshesh}\n",
    "    \n",
    "    # number of states, controls\n",
    "    nx = mpar['numstates'] # number of states\n",
    "    ny = mpar['numcontrols'] # number of controls\n",
    "    NxNx= nx -2 # number of states w/o aggregates\n",
    "    NN = mpar['nm']*mpar['nh'] # number of points in the full grid\n",
    "    \n",
    "        \n",
    "    ## Indexes for LHS/RHS\n",
    "    # Indexes for controls\n",
    "    mutil_cind = np.array(range(NN))\n",
    "    PIind = 1*NN\n",
    "    Yind = 1*NN+1\n",
    "    #Gind = 1*NN+2\n",
    "    Wind = 1*NN+2\n",
    "    Profitind = 1*NN+3\n",
    "    Nind = 1*NN+4\n",
    "    #Tind = 1*NN+6\n",
    "    Bind = 1*NN+5\n",
    "    Gind = 1*NN+6\n",
    "    \n",
    "    # Initialize LHS and RHS\n",
    "    LHS = np.zeros((nx+Gind+1,1))\n",
    "    RHS = np.zeros((nx+Gind+1,1))\n",
    "    \n",
    "    # Indexes for states\n",
    "    #distr_ind = np.arange(mpar['nm']*mpar['nh']-mpar['nh']-1)\n",
    "    marginal_mind = range(mpar['nm']-1)\n",
    "    marginal_hind = range(mpar['nm']-1,mpar['nm']+mpar['nh']-3)\n",
    "    \n",
    "    RBind = NxNx\n",
    "    Sind = NxNx+1\n",
    "    \n",
    "    ## Control variables\n",
    "    #Control = ControlSS.copy()+Control_sparse.copy()\n",
    "    #Controlminus = ControlSS.copy()+Controlminus_sparse.copy()\n",
    "    Control = np.multiply(ControlSS.copy(),(1+Gamma_control.copy().dot(Control_sparse.copy())))\n",
    "    Controlminus = np.multiply(ControlSS.copy(),(1+Gamma_control.copy().dot(Controlminus_sparse.copy())))\n",
    "    \n",
    "    Control[-oc:] = ControlSS[-oc:].copy() + Gamma_control[-oc:,:].copy().dot(Control_sparse.copy())\n",
    "    Controlminus[-oc:] = ControlSS[-oc:].copy() + Gamma_control[-oc:,:].copy().dot(Controlminus_sparse.copy())\n",
    "    \n",
    "            \n",
    "    ## State variables\n",
    "    # read out marginal histogram in t+1, t\n",
    "    Distribution = StateSS[:-2].copy() + Gamma_state.copy().dot(State[:NxNx].copy())\n",
    "    Distributionminus = StateSS[:-2].copy() + Gamma_state.copy().dot(Stateminus[:NxNx].copy())\n",
    "\n",
    "    # Aggregate Endogenous States\n",
    "    RB = StateSS[-2] + State[-2]\n",
    "    RBminus = StateSS[-2] + Stateminus[-2]\n",
    "    \n",
    "    # Aggregate Exogenous States\n",
    "    S = StateSS[-1] + State[-1]\n",
    "    Sminus = StateSS[-1] + Stateminus[-1]\n",
    "    \n",
    "    ## Split the control vector into items with names\n",
    "    # Controls\n",
    "    mutil_c = mutil(Control[mutil_cind].copy())\n",
    "    mutil_cminus = mutil(Controlminus[mutil_cind].copy())\n",
    "    \n",
    "    # Aggregate Controls (t+1)\n",
    "    PI = np.exp(Control[PIind])\n",
    "    Y = np.exp(Control[Yind])\n",
    "    B = Control[Bind]\n",
    "    \n",
    "    # Aggregate Controls (t)\n",
    "    PIminus = np.exp(Controlminus[PIind])\n",
    "    Yminus = np.exp(Controlminus[Yind])\n",
    "    #Gminus = np.exp(Controlminus[Gind])\n",
    "    Wminus = np.exp(Controlminus[Wind])\n",
    "    Profitminus = np.exp(Controlminus[Profitind])\n",
    "    Nminus = np.exp(Controlminus[Nind])\n",
    "    #Tminus = np.exp(Controlminus[Tind])\n",
    "    Bminus = Controlminus[Bind]\n",
    "    Gminus = Controlminus[Gind]\n",
    "    \n",
    "    ## Write LHS values\n",
    "    # Controls\n",
    "    LHS[nx+mutil_cind.copy()] = invmutil(mutil_cminus.copy())\n",
    "    LHS[nx+Yind] = Yminus\n",
    "    LHS[nx+Wind] = Wminus\n",
    "    LHS[nx+Profitind] = Profitminus\n",
    "    LHS[nx+Nind] = Nminus\n",
    "    #LHS[nx+Tind] = Tminus\n",
    "    LHS[nx+Bind] = Bminus\n",
    "    LHS[nx+Gind] = Gminus\n",
    "    \n",
    "    # States\n",
    "    # Marginal Distributions (Marginal histograms)\n",
    "    #LHS[distr_ind] = Distribution[:mpar['nm']*mpar['nh']-1-mpar['nh']].copy()\n",
    "    LHS[marginal_mind] = Distribution[:mpar['nm']-1]\n",
    "    LHS[marginal_hind] = Distribution[mpar['nm']:mpar['nm']+mpar['nh']-2]\n",
    "    \n",
    "    LHS[RBind] = RB\n",
    "    LHS[Sind] = S\n",
    "    \n",
    "    # take into account that RB is in logs\n",
    "    RB = np.exp(RB)\n",
    "    RBminus = np.exp(RBminus) \n",
    "    \n",
    "    ## Set of differences for exogenous process\n",
    "    RHS[Sind] = par['rhoS']*Sminus\n",
    "    \n",
    "    if aggrshock == 'MP':\n",
    "        EPS_TAYLOR = Sminus\n",
    "        TFP = 1.0\n",
    "    elif aggrshock == 'TFP':\n",
    "        TFP = np.exp(Sminus)\n",
    "        EPS_TAYLOR = 0\n",
    "    elif aggrshock == 'Uncertainty':\n",
    "        TFP = 1.0\n",
    "        EPS_TAYLOR = 0\n",
    "   \n",
    "        #Tauchen style for probability distribution next period\n",
    "        P = ExTransitions(np.exp(Sminus), grid, mpar, par)['P_H']\n",
    "        \n",
    "    \n",
    "    marginal_mminus = np.transpose(Distributionminus[:mpar['nm']].copy())\n",
    "    marginal_hminus = np.transpose(Distributionminus[mpar['nm']:mpar['nm']+mpar['nh']].copy())\n",
    "    \n",
    "    Hminus = np.sum(np.multiply(grid['h'][:-1],marginal_hminus[:,:-1]))\n",
    "    Lminus = np.sum(np.multiply(grid['m'],marginal_mminus))\n",
    "    \n",
    "    RHS[nx+Bind] = Lminus\n",
    "    \n",
    "    # Calculate joint distributions\n",
    "    cumdist = np.zeros((mpar['nm']+1,mpar['nh']+1))\n",
    "    cumdist[1:,1:] = Copula(np.squeeze(np.asarray(np.cumsum(marginal_mminus))),np.squeeze(np.asarray(np.cumsum(marginal_hminus)))).T\n",
    "    JDminus = np.diff(np.diff(cumdist,axis=0),axis=1)\n",
    "    \n",
    "    ## Aggregate Output\n",
    "    mc = par['mu'] - (par['beta']* np.log(PI)*Y/Yminus - np.log(PIminus))/par['kappa']\n",
    "    \n",
    "    RHS[nx+Nind] = (par['tau']*TFP*par['alpha']*grid['K']**(1-par['alpha'])*np.asarray(mc))**(1/(1-par['alpha']+par['gamma']))\n",
    "    RHS[nx+Yind] = (TFP*np.asarray(Nminus)**par['alpha']*grid['K']**(1-par['alpha']))\n",
    "    \n",
    "    # Wage Rate\n",
    "    RHS[nx+Wind] = TFP * par['alpha'] * mc *(grid['K']/np.asarray(Nminus))**(1-par['alpha'])\n",
    "    \n",
    "    # Profits for Enterpreneurs\n",
    "    RHS[nx+Profitind] = (1-mc)*Yminus - Yminus*(1/(1-par['mu']))/par['kappa']/2*np.log(PIminus)**2\n",
    "    \n",
    "       \n",
    "    ## Wages net of leisure services\n",
    "    WW = par['gamma']/(1+par['gamma'])*(np.asarray(Nminus)/Hminus)*np.asarray(Wminus)*np.ones((mpar['nm'],mpar['nh']))\n",
    "    WW[:,-1] = Profitminus*par['profitshare']\n",
    "    \n",
    "    ## Incomes (grids)\n",
    "    inclabor = par['tau']*WW.copy()*meshes['h'].copy()\n",
    "    incmoney = np.multiply(meshes['m'].copy(),(RBminus/PIminus+(meshes['m']<0)*par['borrwedge']/PIminus))\n",
    "    inc = {'labor':inclabor, 'money':incmoney}\n",
    "    \n",
    "    ## Update policies\n",
    "    RBaux = (RB+(meshes['m']<0).copy()*par['borrwedge'])/PI\n",
    "    EVm = np.reshape(np.reshape(np.multiply(RBaux.flatten().T.copy(),mutil_c),(mpar['nm'],mpar['nh']),order='F').dot(np.transpose(P.copy())),(mpar['nm'],mpar['nh']),order='F')\n",
    "    \n",
    "    result_EGM_policyupdate = EGM_policyupdate(EVm,PIminus,RBminus,inc,meshes,grid,par,mpar)\n",
    "    c_star = result_EGM_policyupdate['c_star']\n",
    "    m_star = result_EGM_policyupdate['m_star']\n",
    "    \n",
    "    ## Update Marginal Value Bonds\n",
    "    mutil_c_aux = mutil(c_star.copy())\n",
    "    RHS[nx+mutil_cind] = invmutil(np.asmatrix(mutil_c_aux.flatten(order='F').copy()).T)\n",
    "    \n",
    "    ## Differences for distriutions\n",
    "    # find next smallest on-grid value for money choices\n",
    "    weightl1 = np.zeros((mpar['nm'],mpar['nh'],mpar['nh']))\n",
    "    weightl2 = np.zeros((mpar['nm'],mpar['nh'],mpar['nh']))\n",
    "    \n",
    "    # Adjustment case\n",
    "    result_genweight = GenWeight(m_star,grid['m'])\n",
    "    Dist_m = result_genweight['weight'].copy()\n",
    "    idm = result_genweight['index'].copy()\n",
    "    \n",
    "    idm = np.tile(np.asmatrix(idm.copy().flatten('F')).T,(1,mpar['nh']))\n",
    "    idh = np.kron(range(mpar['nh']),np.ones((1,mpar['nm']*mpar['nh']))).astype(np.int64)\n",
    "    \n",
    "    indexl1 = np.ravel_multi_index([idm.flatten(order='F'),idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nh']),order='F')\n",
    "    indexl2 = np.ravel_multi_index([idm.flatten(order='F')+1,idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nh']),order='F')\n",
    "    \n",
    "    for hh in range(mpar['nh']):\n",
    "        \n",
    "        # corresponding weights\n",
    "        weightl1_aux = (1-Dist_m[:,hh])   ## dimension of Dist_m :1\n",
    "        weightl2_aux = Dist_m[:,hh]   ## dimension of Dist_m :1\n",
    "        \n",
    "        # dimensions (m*k,h',h)\n",
    "        weightl1[:,:,hh] = np.outer(weightl1_aux,P[hh,:])\n",
    "        weightl2[:,:,hh] = np.outer(weightl2_aux,P[hh,:])\n",
    "        \n",
    "    weightl1= np.ndarray.transpose(weightl1.copy(),(0,2,1))       \n",
    "    weightl2= np.ndarray.transpose(weightl2.copy(),(0,2,1))       \n",
    "    \n",
    "    rowindex = np.tile(range(mpar['nm']*mpar['nh']),(1,2*mpar['nh']))\n",
    "    \n",
    "    H = sp.coo_matrix((np.hstack((weightl1.flatten(order='F'),weightl2.flatten(order='F'))), \n",
    "                   (np.squeeze(rowindex), np.hstack((np.squeeze(np.asarray(indexl1)),np.squeeze(np.asarray(indexl2)))) ))  , shape=(mpar['nm']*mpar['nh'],mpar['nm']*mpar['nh']) )\n",
    "\n",
    "        \n",
    "    JD_new = JDminus.flatten(order='F').copy().dot(H.todense())\n",
    "    JD_new = np.reshape(JD_new.copy(),(mpar['nm'],mpar['nh']),order='F')\n",
    "    \n",
    "    # Next period marginal histograms\n",
    "    # liquid assets\n",
    "    aux_m = np.sum(JD_new.copy(),1)\n",
    "    RHS[marginal_mind] = aux_m[:-1].copy()\n",
    "    \n",
    "    # human capital\n",
    "    aux_h = np.sum(JD_new.copy(),0)\n",
    "    RHS[marginal_hind] = aux_h[:,:-2].copy().T\n",
    "    \n",
    "    ## Third Set: Government Budget constraint\n",
    "    # Return on bonds (Taylor Rule)\n",
    "    RHS[RBind] = np.log(par['RB'])+par['rho_R']*np.log(RBminus/par['RB']) + np.log(PIminus/par['PI'])*((1.-par['rho_R'])*par['theta_pi'])+EPS_TAYLOR\n",
    "    \n",
    "    \n",
    "    # Fiscal rule\n",
    "    \n",
    "    # Inflation jumps to equilibrate real bond supply and demand\n",
    "    \n",
    "    if par['tau'] < 1:\n",
    "       RHS[nx+Gind] = targets['G']*np.exp(-par['gamma_b']*np.log(Bminus/targets['B']) - par['gamma_pi']*np.log(PIminus/par['PI'])) \n",
    "       tax = (1-par['tau'])*Wminus*Nminus + (1-par['tau'])*Profitminus\n",
    "       RHS[nx+PIind] = (Bminus*RBminus/PIminus + Gminus - tax)\n",
    "       LHS[nx+PIind] = B\n",
    "    else:\n",
    "       RHS[nx+Gind] = targets['G'] \n",
    "       RHS[nx+PIind] = targets['B']\n",
    "       LHS[nx+PIind] = B\n",
    "    \n",
    "    \n",
    "    ## Difference\n",
    "    Difference = InvGamma.dot( (LHS-RHS)/np.vstack(( np.ones((nx,1)),ControlSS[:-oc],np.ones((oc,1)) )) )\n",
    "    \n",
    "          \n",
    "    \n",
    "    return {'Difference':Difference, 'LHS':LHS, 'RHS':RHS, 'JD_new': JD_new, 'c_star':c_star,'m_star':m_star,'P':P}\n",
    "\n",
    "\n",
    "def EGM_policyupdate(EVm,PIminus,RBminus,inc,meshes,grid,par,mpar):\n",
    "    \n",
    "    ## EGM step 1\n",
    "    EMU = par['beta']*np.reshape(EVm.copy(),(mpar['nm'],mpar['nh']),order = 'F')\n",
    "    c_new = 1./np.power(EMU,(1./par['xi']))\n",
    "    # Calculate assets consistent with choices being (m')\n",
    "    # Calculate initial money position from the budget constraint,\n",
    "    # that leads to the optimal consumption choice\n",
    "    m_n_aux = (c_new.copy() + meshes['m'].copy()-inc['labor'].copy())\n",
    "    m_n_aux = m_n_aux.copy()/(RBminus/PIminus+(m_n_aux.copy()<0)*par['borrwedge']/PIminus)\n",
    "    \n",
    "    # Identify binding constraints\n",
    "    binding_constraints = meshes['m'].copy() < np.tile(m_n_aux[0,:].copy(),(mpar['nm'],1))\n",
    "    \n",
    "    # Consumption when drawing assets m' to zero: Eat all resources\n",
    "    Resource = inc['labor'].copy() + inc['money'].copy()\n",
    "    \n",
    "    m_n_aux = np.reshape(m_n_aux.copy(),(mpar['nm'],mpar['nh']),order='F')\n",
    "    c_n_aux = np.reshape(c_new.copy(),(mpar['nm'],mpar['nh']),order='F')\n",
    "    \n",
    "    # Interpolate grid['m'] and c_n_aux defined on m_n_aux over grid['m']\n",
    "    # Check monotonicity of m_n_aux\n",
    "    if np.sum(np.abs(np.diff(np.sign(np.diff(m_n_aux.copy(),axis=0)),axis=0)),axis=1).max() != 0:\n",
    "       print(' Warning: non monotone future liquid asset choice encountered ')\n",
    "       \n",
    "    c_star = np.zeros((mpar['nm'],mpar['nh']))\n",
    "    m_star = np.zeros((mpar['nm'],mpar['nh']))\n",
    "    \n",
    "    for hh in range(mpar['nh']):\n",
    "         \n",
    "        Savings = interp1d(np.squeeze(np.asarray(m_n_aux[:,hh].copy())), grid['m'].copy(), fill_value='extrapolate')\n",
    "        m_star[:,hh] = Savings(grid['m'].copy())\n",
    "        Consumption = interp1d(np.squeeze(np.asarray(m_n_aux[:,hh].copy())), np.squeeze(np.asarray(c_n_aux[:,hh].copy())), fill_value='extrapolate')\n",
    "        c_star[:,hh] = Consumption(grid['m'].copy())\n",
    "    \n",
    "    c_star[binding_constraints] = np.squeeze(np.asarray(Resource[binding_constraints].copy() - grid['m'][0]))\n",
    "    m_star[binding_constraints] = grid['m'].min()\n",
    "    \n",
    "    m_star[m_star>grid['m'][-1]] = grid['m'][-1]\n",
    "    \n",
    "    return {'c_star': c_star, 'm_star': m_star}\n",
    "        \n",
    "###############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Implement Dimensionality Reduction\n",
    "\n",
    "EX2SR=FluctuationsOneAssetIOUs(**EX2SS)\n",
    "\n",
    "## Choose an accuracy of approximation with DCT\n",
    "#EX2SS['par']['accuracy'] = 0.99999 ## TW: does not have accuracy here, not sure why?\n",
    "\n",
    "# Do state reduction \n",
    "SR=EX2SR.StateReduc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Choose an aggregate shock to perturb(one of three shocks: MP, TFP, Uncertainty)\n",
    "\n",
    "#EX2SS['par']['aggrshock']           = 'MP'\n",
    "#EX2SS['par']['rhoS']    = 0.0      # Persistence of variance\n",
    "#EX2SS['par']['sigmaS']  = 0.001    # STD of variance shocks\n",
    "\n",
    "#EX3SS['par']['aggrshock']           = 'TFP'\n",
    "#EX3SS['par']['rhoS']    = 0.95\n",
    "#EX3SS['par']['sigmaS']  = 0.0075\n",
    "    \n",
    "#EX3SS['par']['aggrshock']           = 'Uncertainty'\n",
    "#EX3SS['par']['rhoS']    = 0.84    # Persistence of variance\n",
    "#EX3SS['par']['sigmaS']  = 0.54    # STD of variance shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the results from the state reduction?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The copula represents the joint distribution with a vector of size (504, 501)\n",
      "The dimension of states including exogenous state, is 506\n",
      "It simply stacks all grids of different      \n",
      " state variables regardless of their joint distributions.      \n",
      " This is due to the assumption that the rank order remains the same.\n"
     ]
    }
   ],
   "source": [
    "# Measuring the effectiveness of the state reduction\n",
    "\n",
    "print('What are the results from the state reduction?')\n",
    "#print('Newly added attributes after the operation include \\n'+str(set(SR.keys())-set(EX2SS.keys())))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "#print('To achieve an accuracy of '+str(EX2SS['par']['accuracy'])+'\\n') \n",
    "\n",
    "#print('The dimension of the policy functions is reduced to '+str(SR['indexMUdct'].shape[0]) \\\n",
    "#      +' from '+str(EX2SS['mpar']['nm']*EX2SS['mpar']['nh'])\n",
    "#      )\n",
    "#print('The dimension of the marginal value functions is reduced to '+str(SR['indexVKdct'].shape[0]) \\\n",
    "#      + ' from ' + str(EX3SS['Vk'].shape))\n",
    "#print('The total number of control variables is '+str(SR['Contr'].shape[0])+'='+str(SR['indexMUdct'].shape[0]) + \\\n",
    "#      '+'+str(SR['indexVKdct'].shape[0])+'+ # of other macro controls')\n",
    "print('\\n')\n",
    "print('The copula represents the joint distribution with a vector of size '+str(SR['Gamma_state'].shape) )\n",
    "print('The dimension of states including exogenous state, is ' +str(SR['Xss'].shape[0]))\n",
    "\n",
    "print('It simply stacks all grids of different\\\n",
    "      \\n state variables regardless of their joint distributions.\\\n",
    "      \\n This is due to the assumption that the rank order remains the same.')\n",
    "#print('The total number of state variables is '+str(SR['State'].shape[0]) + '='+\\\n",
    "#     str(SR['Gamma_state'].shape[1])+'+ the number of macro states (like the interest rate)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Illustration\n",
    "\n",
    "#### Policy/value functions\n",
    "\n",
    "Taking the consumption function as an example, we plot consumption by adjusters and non-adjusters over a range of $k$ and $m$ that encompasses x percent of the mass of the distribution function.  \n",
    "\n",
    "We plot the functions for the top and bottom values of the wage $h$ distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Graphical illustration\n",
    "\n",
    "xi = EX2SS['par']['xi']\n",
    "invmutil = lambda x : (1./x)**(1./xi)  \n",
    "\n",
    "### convert marginal utilities back to consumption function\n",
    "mut_StE  =  EX2SS['mutil_c']\n",
    "\n",
    "\n",
    "c_StE = invmutil(mut_StE)\n",
    "\n",
    "\n",
    "### grid values \n",
    "dim_StE = mut_StE.shape\n",
    "mgrid = EX2SS['grid']['m']\n",
    "hgrid = EX2SS['grid']['h']\n",
    "\n",
    "## indexMUdct is one dimension, needs to be unraveled to 3 dimensions\n",
    "\n",
    "#mut_rdc_idx = np.unravel_index(SR['indexMUdct'],dim_StE,order='F')\n",
    "#nb_dct = len(mut_StE.flatten()) \n",
    "#mut_rdc_bool = np.zeros(nb_dct)     # boolean array of 30 x 30 x 4  \n",
    "#for i in range(nb_dct):\n",
    "#    mut_rdc_bool[i]=i in list(SR['indexMUdct'])\n",
    "#mut_rdc_bool_3d = (mut_rdc_bool==1).reshape(dim_StE)\n",
    "#mut_rdc_mask_3d = (mut_rdc_bool).reshape(dim_StE)\n",
    "\n",
    "\n",
    "## get the 95 percent or other percentile of the distribution\n",
    "\n",
    "joint_distr =  EX2SS['joint_distr']\n",
    "#marginal_mk =  EX2SS['joint_distr'].sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## define some functions to be used next\n",
    "\n",
    "def dct2d(x):\n",
    "    x0=sf.dct(x.copy(),axis=0,norm='ortho')\n",
    "    x1=sf.dct(x0.copy(),axis=1,norm='ortho')\n",
    "    return x1\n",
    "\n",
    "def idct2d(x):\n",
    "    x1 = sf.idct(x.copy(),axis=1,norm='ortho')\n",
    "    x0 = sf.idct(x1.copy(),axis=0,norm='ortho')\n",
    "    return x0\n",
    "\n",
    "def DCTApprox(fullgrids,dct_index):\n",
    "    dim=fullgrids.shape\n",
    "    dctcoefs = dct2d(fullgrids)\n",
    "    dctcoefs_rdc = np.zeros(dim)\n",
    "    dctcoefs_rdc[dct_index]=dctcoefs[dct_index]\n",
    "    approxgrids = idct2d(dctcoefs_rdc)\n",
    "    return approxgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cn_StE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8f6d39709b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## get dct compressed c functions at all grids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc_n_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCTApprox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn_StE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmut_rdc_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mc_a_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCTApprox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca_StE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmut_rdc_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cn_StE' is not defined"
     ]
    }
   ],
   "source": [
    "## get dct compressed c functions at all grids \n",
    "\n",
    "c_n_approx = DCTApprox(cn_StE,mut_rdc_idx)\n",
    "c_a_approx = DCTApprox(ca_StE,mut_rdc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## 3D scatter plots of consumption function \n",
    "##    at all grids and grids after dct for both adjusters and non-adjusters\n",
    "\n",
    "\n",
    "## for non-adjusters\n",
    "\n",
    "## full grids \n",
    "#mmgrid,kkgrid = np.meshgrid(mgrid,kgrid)\n",
    "\n",
    "### for adjusters \n",
    "fig = plt.figure(figsize=(14,14))\n",
    "fig.suptitle('Consumption of non-adjusters at grid points of m and k(for different h)',\n",
    "             fontsize=(13))\n",
    "for hgrid_id in range(EX3SS['mpar']['nh']):\n",
    "    ## prepare the reduced grids \n",
    "    hgrid_fix=hgrid_id\n",
    "    \n",
    "    \n",
    "    ## for each h grid, take the 95% mass of m and k as the maximum of the m and k axis \n",
    "    \n",
    "    marginal_mk = joint_distr[:,:,hgrid_fix]\n",
    "    marginal_m = marginal_mk.sum(axis=0)\n",
    "    marginal_k = marginal_mk.sum(axis=1)\n",
    "    mmax = mgrid[(np.abs(marginal_m.cumsum()-mass_pct*marginal_m.cumsum().max())).argmin()]\n",
    "    kmax = kgrid[(np.abs(marginal_k.cumsum()-mass_pct*marginal_k.cumsum().max())).argmin()]\n",
    "\n",
    "    ## plots \n",
    "    ax = fig.add_subplot(2,2,hgrid_id+1, projection='3d')\n",
    "    ax.plot_surface(mmgrid,kkgrid,c_n_rdc,cmap='Blues',\n",
    "                    label='StE(after dct):non-adjuster')\n",
    "    ax.scatter(mmgrid,kkgrid,cn_StE[:,:,hgrid_fix],marker='v',color='red',\n",
    "               label='StE(before dct): non-adjuster')\n",
    "    ax.set_xlabel('m',fontsize=13)\n",
    "    ax.set_ylabel('k',fontsize=13)\n",
    "    ax.set_zlabel(r'$c_a(m,k)$',fontsize=13)\n",
    "    #ax.set_xlim([0,mmax])\n",
    "    #ax.set_ylim([0,kmax])\n",
    "    ax.set_title(r'$h({})$'.format(hgrid_fix))\n",
    "    ax.view_init(20, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation\n",
    "\n",
    "- For a given grid value of productivity, the remaining grid points after DCT to represent the whole consumption function are concentrated in low values of $k$ and $m$. This is because the slopes of the surfaces of marginal utility are changing the most in these regions.  For larger values of $k$ and $m$ the functions become smooth and only slightly concave, so they can be represented by many fewer points\n",
    "- For different grid values of productivity (2 sub plots), the numbers of grid points in the DCT operation differ. From the lowest to highest values of productivity, there are 78, 33, 25 and 18 grid points, respectively. They add up to the total number of gridpoints of 154 after DCT operation, as we noted above for marginal utility function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of states \n",
    "\n",
    "- We first plot the distribution of $k$ fixing $m$ and $h$. Next, we plot the joint distribution of $m$ and $k$ only fixing $h$ in 3-dimenstional space.  \n",
    "- The joint-distribution can be represented by marginal distributions of $m$, $k$ and $h$ and a copula that describes the correlation between the three states. The former is straightfoward. We plot the copula only. The copula is essentially a multivariate cummulative distribution function where each marginal is uniform. (Translation from the uniform to the appropriate nonuniform distribution is handled at a separate stage).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EX3SS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6f8a28721bb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Marginalize along h grids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjoint_distr\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mEX3SS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'joint_distr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mjoint_distr_km\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEX3SS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'joint_distr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EX3SS' is not defined"
     ]
    }
   ],
   "source": [
    "### Marginalize along h grids\n",
    "\n",
    "joint_distr =  EX3SS['joint_distr']\n",
    "joint_distr_km = EX3SS['joint_distr'].sum(axis=2)\n",
    "\n",
    "### Plot distributions in 2 dimensional graph \n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.suptitle('Marginal distribution of k at different m')\n",
    "\n",
    "for hgrid_id in range(EX3SS['mpar']['nh']):\n",
    "    ax = plt.subplot(2,2,hgrid_id+1)\n",
    "    ax.set_title(r'$h({})$'.format(hgrid_id))\n",
    "    ax.set_xlabel('k',size=12)\n",
    "    for id in range(EX3SS['mpar']['nm']):   \n",
    "        ax.plot(kgrid,joint_distr[id,:,hgrid_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Plot joint distribution of k and m in 3d graph\n",
    "\n",
    "fig = plt.figure(figsize=(14,14))\n",
    "fig.suptitle('Joint distribution of m and k(for different h)',\n",
    "             fontsize=(13))\n",
    "for hgrid_id in range(EX3SS['mpar']['nh']):\n",
    "    ## plots \n",
    "    ax = fig.add_subplot(2,2,hgrid_id+1, projection='3d')\n",
    "    ax.plot_surface(mmgrid,kkgrid,joint_distr[:,:,hgrid_fix], rstride=1, cstride=1,\n",
    "                    cmap='viridis', edgecolor='none')\n",
    "    ax.set_xlabel('m',fontsize=13)\n",
    "    ax.set_ylabel('k',fontsize=13)\n",
    "    #ax.set_zlabel(r'$p(m,k)$',fontsize=10)\n",
    "    ax.set_title(r'$h({})$'.format(hgrid_id))\n",
    "    ax.set_xlim(0,400)\n",
    "    ax.view_init(20, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the CDFs in StE copula have 4 modes, corresponding to the number of $h$ gridpoints. Each of the four parts of the cdf is a joint-distribution of $m$ and $k$.  It can be presented in 3-dimensional graph as below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EX3SS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-773729ac58cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Plot the copula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEX3SS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Copula'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# important: 4,30,30 not 30,30,4?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EX3SS' is not defined"
     ]
    }
   ],
   "source": [
    "## Plot the copula \n",
    "\n",
    "cdf=EX3SS['Copula']['value'].reshape(4,30,30)   # important: 4,30,30 not 30,30,4? \n",
    "\n",
    "fig = plt.figure(figsize=(14,14))\n",
    "fig.suptitle('Copula of m and k(for different h)',\n",
    "             fontsize=(13))\n",
    "for hgrid_id in range(EX3SS['mpar']['nh']):\n",
    "    ## plots \n",
    "    ax = fig.add_subplot(2,2,hgrid_id+1, projection='3d')\n",
    "    ax.plot_surface(mmgrid,kkgrid,cdf[hgrid_id,:,:], rstride=1, cstride=1,\n",
    "                    cmap='viridis', edgecolor='None')\n",
    "    ax.set_xlabel('m',fontsize=13)\n",
    "    ax.set_ylabel('k',fontsize=13)\n",
    "    ax.set_title(r'$h({})$'.format(hgrid_id))\n",
    "    \n",
    "    ## for each h grid, take the 95% mass of m and k as the maximum of the m and k axis \n",
    "    \n",
    "    marginal_mk = joint_distr[:,:,hgrid_id]\n",
    "    marginal_m = marginal_mk.sum(axis=0)\n",
    "    marginal_k = marginal_mk.sum(axis=1)\n",
    "    mmax = mgrid[(np.abs(marginal_m.cumsum()-mass_pct*marginal_m.cumsum().max())).argmin()]\n",
    "    kmax = kgrid[(np.abs(marginal_k.cumsum()-mass_pct*marginal_k.cumsum().max())).argmin()]\n",
    "    \n",
    "    #ax.set_xlim(0,mmax)\n",
    "    #ax.set_ylim(0,kmax)\n",
    "    ax.view_init(30, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the assumption that the copula remains the same after aggregate risk is introduced, we can use the same copula and the marginal distributions to recover the full joint-distribution of the states.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: what do we achieve after the transformation?\n",
    "\n",
    "- Using the DCT, the dimension of the policy and value functions are reduced from 3600 to 154 and 94, respectively.\n",
    "- By marginalizing the joint distribution with the fixed copula assumption, the marginal distribution is of dimension 64 compared to its joint distribution of a dimension of 3600.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "6202365/L5GBWHBM": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "container-title": "Journal of Economic Dynamics and Control",
     "id": "undefined",
     "issue": "1",
     "issued": {
      "month": 1,
      "year": 2010
     },
     "note": "Citation Key: reiterBackward",
     "page": "28-35",
     "page-first": "28",
     "title": "Solving the Incomplete Markets Model with Aggregate Uncertainty by Backward Induction",
     "type": "article-journal",
     "volume": "34"
    },
    "6202365/UKUXJHCN": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "id": "6202365/UKUXJHCN",
     "note": "Citation Key: reiter2002recursive \nbibtex*[publisher=Citeseer]",
     "title": "Recursive computation of heterogeneous agent models",
     "type": "article-journal"
    },
    "6202365/VPUXICUR": {
     "author": [
      {
       "family": "Krusell",
       "given": "Per"
      },
      {
       "family": "Smith",
       "given": "Anthony A."
      }
     ],
     "container-title": "Journal of Political Economy",
     "id": "6202365/VPUXICUR",
     "issue": "5",
     "issued": {
      "year": 1998
     },
     "page": "867–896",
     "page-first": "867",
     "title": "Income and Wealth Heterogeneity in the Macroeconomy",
     "type": "article-journal",
     "volume": "106"
    },
    "6202365/WN76AW6Q": {
     "author": [
      {
       "family": "SeHyoun Ahn, Greg Kaplan, Benjamin Moll, Thomas Winberry",
       "given": ""
      },
      {
       "family": "Wolf",
       "given": "Christian"
      }
     ],
     "editor": [
      {
       "family": "Parker",
       "given": "Jonathan"
      },
      {
       "family": "Martin S. Eichenbaum",
       "given": "Organizers"
      }
     ],
     "id": "6202365/WN76AW6Q",
     "issued": {
      "year": 2017
     },
     "note": "Citation Key: akmwwInequality \nbibtex*[booktitle=NBER Macroeconomics Annual;publisher=MIT Press;location=Cambridge, MA]",
     "title": "When Inequality Matters for Macro and Macro Matters for Inequality",
     "type": "article-journal",
     "volume": "32"
    },
    "undefined": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "container-title": "Journal of Economic Dynamics and Control",
     "id": "undefined",
     "issue": "1",
     "issued": {
      "month": 1,
      "year": 2010
     },
     "note": "Citation Key: reiterBackward",
     "page": "28-35",
     "page-first": "28",
     "title": "Solving the Incomplete Markets Model with Aggregate Uncertainty by Backward Induction",
     "type": "article-journal",
     "volume": "34"
    }
   }
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
